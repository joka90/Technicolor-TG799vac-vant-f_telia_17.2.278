From 02b77cbba6edbc31210f0cd9a887556ec1b7ea17 Mon Sep 17 00:00:00 2001
From: Karl Vogel <karl.vogel@technicolor.com>
Date: Tue, 25 Jun 2013 14:21:58 +0200
Subject: [PATCH 1/2] Adds fullcone nat support to the MASQUERADE target.

Patch was created by Broadcom.
---
 net/ipv4/netfilter/ipt_MASQUERADE.c |  198 +++++++++++++++++++++++++++++++++++
 1 files changed, 198 insertions(+), 0 deletions(-)

--- a/net/ipv4/netfilter/ipt_MASQUERADE.c
+++ b/net/ipv4/netfilter/ipt_MASQUERADE.c
@@ -20,13 +20,147 @@
 #include <net/checksum.h>
 #include <net/route.h>
 #include <net/netfilter/nf_nat_rule.h>
+#include <net/netfilter/nf_conntrack_zones.h>
 #include <linux/netfilter_ipv4.h>
 #include <linux/netfilter/x_tables.h>
 
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#include <net/netfilter/nf_conntrack_helper.h>
+#include <net/netfilter/nf_nat.h>
+#include <net/netfilter/nf_nat_rule.h>
+#include <net/netfilter/nf_nat_helper.h>
+
 MODULE_LICENSE("GPL");
 MODULE_AUTHOR("Netfilter Core Team <coreteam@netfilter.org>");
 MODULE_DESCRIPTION("Xtables: automatic-address SNAT");
 
+/****************************************************************************/
+static void bcm_nat_expect(struct nf_conn *ct,
+			   struct nf_conntrack_expect *exp)
+{
+	struct nf_nat_ipv4_range range;
+
+	/* This must be a fresh one. */
+	BUG_ON(ct->status & IPS_NAT_DONE_MASK);
+
+	/* Change src to where new ct comes from */
+	range.flags = NF_NAT_RANGE_MAP_IPS;
+	range.min_ip = range.max_ip =
+		ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.src.u3.ip;
+	nf_nat_setup_info(ct, &range, NF_NAT_MANIP_SRC);
+	 
+	/* For DST manip, map port here to where it's expected. */
+	range.flags = (NF_NAT_RANGE_MAP_IPS | NF_NAT_RANGE_PROTO_SPECIFIED);
+	range.min = range.max = exp->saved_proto;
+	range.min_ip = range.max_ip = exp->saved_ip;
+	nf_nat_setup_info(ct, &range, NF_NAT_MANIP_DST);
+}
+
+/****************************************************************************/
+static int bcm_nat_help(struct sk_buff *skb, unsigned int protoff,
+			struct nf_conn *ct, enum ip_conntrack_info ctinfo)
+{
+	int dir = CTINFO2DIR(ctinfo);
+	struct nf_conn_help *help = nfct_help(ct);
+	struct nf_conntrack_expect *exp;
+	
+	if (dir != IP_CT_DIR_ORIGINAL ||
+	    help->expecting[NF_CT_EXPECT_CLASS_DEFAULT])
+		return NF_ACCEPT;
+
+	pr_debug("bcm_nat: packet[%d bytes] ", skb->len);
+	nf_ct_dump_tuple(&ct->tuplehash[dir].tuple);
+	pr_debug("reply: ");
+	nf_ct_dump_tuple(&ct->tuplehash[!dir].tuple);
+	
+	/* Create expect */
+	if ((exp = nf_ct_expect_alloc(ct)) == NULL)
+		return NF_ACCEPT;
+
+	nf_ct_expect_init(exp, NF_CT_EXPECT_CLASS_DEFAULT, AF_INET, NULL,
+			  &ct->tuplehash[!dir].tuple.dst.u3, IPPROTO_UDP,
+			  NULL, &ct->tuplehash[!dir].tuple.dst.u.udp.port);
+	exp->flags = NF_CT_EXPECT_PERMANENT;
+	exp->saved_ip = ct->tuplehash[dir].tuple.src.u3.ip;
+	exp->saved_proto.udp.port = ct->tuplehash[dir].tuple.src.u.udp.port;
+	exp->dir = !dir;
+	exp->expectfn = bcm_nat_expect;
+
+	/* Setup expect */
+	nf_ct_expect_related(exp);
+	nf_ct_expect_put(exp);
+	pr_debug("bcm_nat: expect setup\n");
+
+	return NF_ACCEPT;
+}
+
+/****************************************************************************/
+static struct nf_conntrack_expect_policy bcm_nat_exp_policy __read_mostly = {
+	.max_expected 	= 1000,
+	.timeout	= 240,
+};
+
+/****************************************************************************/
+static struct nf_conntrack_helper nf_conntrack_helper_bcm_nat __read_mostly = {
+	.name = "BCM-NAT",
+	.me = THIS_MODULE,
+	.tuple.src.l3num = AF_INET,
+	.tuple.dst.protonum = IPPROTO_UDP,
+	.expect_policy = &bcm_nat_exp_policy,
+	.expect_class_max = 1,
+	.help = bcm_nat_help,
+};
+
+/****************************************************************************/
+static inline int find_exp(__be32 ip, __be16 port, struct nf_conn *ct)
+{
+	struct nf_conntrack_tuple tuple;
+	struct nf_conntrack_expect *i = NULL;
+
+	
+	memset(&tuple, 0, sizeof(tuple));
+	tuple.src.l3num = AF_INET;
+	tuple.dst.protonum = IPPROTO_UDP;
+	tuple.dst.u3.ip = ip;
+	tuple.dst.u.udp.port = port;
+
+	rcu_read_lock();
+	i = __nf_ct_expect_find(nf_ct_net(ct), nf_ct_zone(ct), &tuple);
+	rcu_read_unlock();
+
+	return i != NULL;
+}
+
+/****************************************************************************/
+static inline struct nf_conntrack_expect *find_fullcone_exp(struct nf_conn *ct)
+{
+	struct nf_conntrack_tuple * tp =
+		&ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple;
+	struct net *net = nf_ct_net(ct);
+	struct nf_conntrack_expect * exp = NULL;
+	struct nf_conntrack_expect * i;
+	struct hlist_node *n;
+	unsigned int h;
+
+	rcu_read_lock();
+	for (h = 0; h < nf_ct_expect_hsize; h++) {
+		hlist_for_each_entry_rcu(i, n, &net->ct.expect_hash[h], hnode) {
+			if (i->saved_ip == tp->src.u3.ip &&
+		    	    i->saved_proto.all == tp->src.u.all &&
+		    	    i->tuple.dst.protonum == tp->dst.protonum &&
+		    	    i->tuple.src.u3.ip == 0 &&
+		    	    i->tuple.src.u.udp.port == 0) {
+				exp = i;
+				break;
+			}
+		}
+	}
+	rcu_read_unlock();
+
+	return exp;
+}
+
 /* FIXME: Multiple targets. --RR */
 static int masquerade_tg_check(const struct xt_tgchk_param *par)
 {
@@ -78,6 +212,69 @@ masquerade_tg(struct sk_buff *skb, const
 
 	nat->masq_index = par->out->ifindex;
 
+	if (mr->range[0].min_ip != 0 /* nat_mode == full cone */
+	    && (nfct_help(ct) == NULL || nfct_help(ct)->helper == NULL)
+	    && nf_ct_protonum(ct) == IPPROTO_UDP) {
+		unsigned int ret;
+		u_int16_t minport;
+		u_int16_t maxport;
+		struct nf_conntrack_expect *exp;
+
+		pr_debug("bcm_nat: need full cone NAT\n");
+
+		/* Choose port */
+		spin_lock_bh(&nf_conntrack_lock);
+		/* Look for existing expectation */
+		exp = find_fullcone_exp(ct);
+		if (exp) {
+			minport = maxport = exp->tuple.dst.u.udp.port;
+			pr_debug("bcm_nat: existing mapped port = %hu\n",
+			       	 ntohs(minport));
+		} else { /* no previous expect */
+			u_int16_t newport, tmpport;
+			
+			minport = mr->range[0].min.all == 0? 
+				ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple.src.
+				u.udp.port : mr->range[0].min.all;
+			maxport = mr->range[0].max.all == 0? 
+				htons(65535) : mr->range[0].max.all;
+			for (newport = ntohs(minport),tmpport = ntohs(maxport); 
+			     newport <= tmpport; newport++) {
+			     	if (!find_exp(newsrc, htons(newport), ct)) {
+					pr_debug("bcm_nat: new mapped port = "
+					       	 "%hu\n", newport);
+					minport = maxport = htons(newport);
+					break;
+				}
+			}
+		}
+		spin_unlock_bh(&nf_conntrack_lock);
+
+		/*
+		newrange = ((struct nf_nat_range)
+			{ mr->range[0].flags | IP_NAT_RANGE_MAP_IPS |
+			  IP_NAT_RANGE_PROTO_SPECIFIED, newsrc, newsrc,
+		  	  mr->range[0].min, mr->range[0].max });
+		*/
+		newrange.flags = mr->range[0].flags | NF_NAT_RANGE_MAP_IPS |
+			NF_NAT_RANGE_PROTO_SPECIFIED;
+		newrange.max_ip = newrange.min_ip = newsrc;
+		newrange.min.udp.port = newrange.max.udp.port = minport;
+	
+		/* Set ct helper */
+		ret = nf_nat_setup_info(ct, &newrange, NF_NAT_MANIP_SRC);
+		if (ret == NF_ACCEPT) {
+			struct nf_conn_help *help = nfct_help(ct);
+			if (help == NULL)
+				help = nf_ct_helper_ext_add(ct, GFP_ATOMIC);
+			if (help != NULL) {
+				help->helper = &nf_conntrack_helper_bcm_nat;
+				pr_debug("bcm_nat: helper set\n");
+			}
+		}
+		return ret;
+	}
+
 	/* Transfer from original range. */
 	newrange = ((struct nf_nat_ipv4_range)
 		{ mr->range[0].flags | NF_NAT_RANGE_MAP_IPS,
@@ -164,6 +361,7 @@ static int __init masquerade_tg_init(voi
 
 static void __exit masquerade_tg_exit(void)
 {
+	nf_conntrack_helper_unregister(&nf_conntrack_helper_bcm_nat);
 	xt_unregister_target(&masquerade_tg_reg);
 	unregister_netdevice_notifier(&masq_dev_notifier);
 	unregister_inetaddr_notifier(&masq_inet_notifier);
